{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projeto realizado por Isabella Rocha de Oliveira\n",
    "Professor Raul Ikeda\n",
    "Engenharia da Computação - Insper\n",
    "Visão Computacional Avançada - 2018.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 09 - Fluxo Ótico\n",
    "\n",
    "Exemplo adaptado do link: https://docs.opencv.org/3.4/d7/d8b/tutorial_py_lucas_kanade.html\n",
    "\n",
    "Referências: \n",
    "    1. Szeilisk - Cap 8.4\n",
    "    1. Artigo Bouguet - Pyramidal Implementation of the Lucas Kanade Feature Tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.2\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "\n",
    "#!pip install opencv-python\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "1. Realizar o download das imagens no Blackboard e verificar se o notebook consegue abri-las:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre uma imagem em gray scale\n",
    "img = cv.imread('./Imagens/frame_0050.jpg', 0)\n",
    "\n",
    "# Exibe a imagem\n",
    "cv.imshow('image',img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "2. Detectar alguns pontos interessantes nela usando o método visto na aula passada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre a imagem\n",
    "img = cv.imread('./Imagens/frame_0050.jpg')\n",
    "\n",
    "# Converte para Grayscale\n",
    "bw = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Parametriza a funcao do OpenCV\n",
    "params = dict( maxCorners = 100,\n",
    "               qualityLevel = 0.3,\n",
    "               minDistance = 7,\n",
    "               blockSize = 7 )\n",
    "\n",
    "# Funcao que retorna uma lista de pontos\n",
    "pts = cv.goodFeaturesToTrack(bw, mask = None, **params)\n",
    "\n",
    "## Plota os pontos na imagem:\n",
    "\n",
    "# Gera cores de forma aleatória\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Insere uma marcação em cada ponto:\n",
    "for i,pt in enumerate(pts):\n",
    "        a,b = pt.ravel()\n",
    "        img = cv.circle(img,(a,b),5,color[i].tolist(),-1)\n",
    "\n",
    "# Exibe a imagem\n",
    "cv.imshow('image',img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "3. Agora vamos realizar o tracking dos pontos usando fluxo ótico. \n",
    "\n",
    "  * Ver o artigo do Bouguet no Blackboard para mais detalhes.\n",
    "  * Fonte das imagens: http://www.cvg.reading.ac.uk/PETS2009/a.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametriza a funcao do OpenCV\n",
    "dt_params = dict( maxCorners = 100,\n",
    "                  qualityLevel = 0.3,\n",
    "                  minDistance = 7,\n",
    "                  blockSize = 7 )\n",
    "\n",
    "# Parametriza o Lucas-Kanade\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Gera cores de forma aleatória\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Detecta os pontos no primeiro frame. Será usado como base na próxima imagem.\n",
    "previous = cv.imread('./Imagens/frame_0050.jpg')\n",
    "previous_gray = cv.cvtColor(previous, cv.COLOR_BGR2GRAY)\n",
    "p0 = cv.goodFeaturesToTrack(previous_gray, mask = None, **dt_params)\n",
    "\n",
    "# Cria uma máscara para imprimir o rastro.\n",
    "mask = np.zeros_like(previous)\n",
    "\n",
    "# Abre o restante das imagens\n",
    "for i in range(51,71):\n",
    "\n",
    "    actual = cv.imread('./Imagens/frame_{:04d}.jpg'.format(i))\n",
    "    \n",
    "    actual_gray = cv.cvtColor(actual, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calcula o Fluxo Otico\n",
    "    p1, st, err = cv.calcOpticalFlowPyrLK(previous_gray, actual_gray, p0, None, **lk_params)\n",
    "    \n",
    "    # Seleciona somente os melhores pontos\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "    \n",
    "    # Desenha as trilhas para cada ponto em p1 e p0\n",
    "    for i,(new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv.line(mask, (a,b),(c,d), [0,0,255], 2)\n",
    "        actual = cv.circle(actual,(a,b),5,color[i].tolist(),-1)\n",
    "        \n",
    "    img = cv.add(actual, mask)\n",
    "    \n",
    "    cv.imshow('frame', img)\n",
    "    cv.waitKey(0)\n",
    "    \n",
    "    # Atualiza a imagem anterior com a imagem atual e copia os pontos.\n",
    "    previous_gray = actual_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto 2-1: Estabilização de imagens\n",
    "\n",
    "**Motivação**: https://www.youtube.com/watch?v=4vt7bGEen2s\n",
    "\n",
    "Agora que você consegue capturar o fluxo ótico entre duas imagens consecultivas, vamos utilizá-lo de modo inverso: como seria uma forma de compensar eventuais oscilações na câmera?\n",
    "\n",
    "Projete um programa que captura as imagens da webcam e realiza a estabilização da imagem. Você notará que se utilizar o programa acima, a estabilização será parcial e falha. Por que?\n",
    "\n",
    "Você deve construir um Jupyter Notebook que utiliza o Dense Optical Flow para corrigir o problema acima. O notebook deve conter comentários acerca da solução usada.\n",
    "\n",
    "O programa base para uso da webcam:\n",
    "\n",
    "```python\n",
    "captura = cv2.VideoCapture(0)\n",
    "\n",
    "# Para não deixar encavalar os frames\n",
    "captura.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    " \n",
    "while(1):\n",
    "    ret, frame = captura.read()\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "   \n",
    "    # Pressione ESC para sair do loop\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    time.sleep(0.5)\n",
    " \n",
    "captura.release()\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "### Entrega: 12/Set 23:59 via GitHub.\n",
    "\n",
    "### Rubrica do Projeto:\n",
    "\n",
    "    I. Não entregou ou entregou apenas um rascunho.\n",
    "    D. O programa faz apenas uma estabilização parcial com os programas da Aula 09.\n",
    "    C. Utiliza o Dense Optical Flow de uma janela no centro da imagem.\n",
    "    B. Utiliza meios para compensar as faixas pretas nos cantos da imagem com algum limite.\n",
    "    A. Consegue realizar a compensação em rotação no eixo de profundidade.\n",
    "    \n",
    "    +1/2 Conceito para implementações que comprovadamente melhoram o desempenho da estabilização.\n",
    "    -1/2 Conceito se o notebook não contiver uma explicação detalhada da solução apresentada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estabilização de imagens por meio do Dense Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar a estabilização da imagem da câmera será utilizado o Dense Optical Flow. As bibliotecas utilizadas nesse projeto são a Numpy e a OpenCV.\n",
    "\n",
    "Com ele é possível obter um vetor de fluxo dos pixels da imagem, então se houver uma movimentação de um objeto na imagem, os pixels relativos à esse objeto terão um fluxo relacionado à movimentação que ocorreu. \n",
    "\n",
    "Neste projeto, esse fluxo será calculado em uma janela central da imagem, de tamanho 50x50 pixels e a estabilização da imagem completa se dará pelo reposicionamento do frame atual levando em consideração o acúmulo de fluxos extraídos da janela central desde o primeiro frame obtido pela câmera, até o anterior ao atual.\n",
    "\n",
    "Para a implementação, à princípio foi delimitado o posicionamento da janela, que é centralizada em relação ao primeiro frame e possui tamanho 50x50 pixels. A câmera também é inicializada e os frames passam a ser exibidos.\n",
    "\n",
    "Logo após foi realizado o corte do frame inicial na delimitação indicada anteriormente.\n",
    "\n",
    "As variáveis que servirão para guardar os acúmulos de fluxo, tanto no eixo horizontal (somax) como no vertical (somay) são inicializadas como 0 pois a janela do primeiro frame será utilizada como referência. \n",
    "\n",
    "Um loop infinito é inicializado e ele apenas para de rodar caso a tecla \"esc\" seja pressionada, interrompendo a exibição dos frames capturados pela câmera. Dentro deste loop, o frame atual é capturado e o mesmo recorte da janela central é realizado. \n",
    "\n",
    "Com a função `cv.calcOpticalFlowFarneback` o frame anterior e o atual são utilizados para calcular o fluxo dos pixels. Essa função retorna uma lista de matrizes com os fluxos dos pixels já separados em relação ao eixo x e ao eixo y. Com esse valor de retorno, a média dos fluxos é obtida por meio da função `np.average`, para ambos os eixos. \n",
    "\n",
    "Como esse valor médio de fluxo é referente ao movimento que aconteceu entre as janelas dos frames, e o objetivo é reposicionar o frame atual para onde os objetos que se movimentaram estavam no frame anterior, o valor desse fluxo médio, em ambos os eixos, é multiplicado por -1, para inverter seu valor e assim poder ser usado para a estabilização.\n",
    "\n",
    "Ambos os valores são somados à variável de acúmulo dos fluxos e isso garante que o valor dessa variável está sempre atualizada em relação à quanto um frame tem que ser deslocado em relação ao frame inicial, pois acontece como se fosse uma soma de vetores (no caso, os fluxos de cada frame vão sendo somados e vai acontecendo a soma de vetores) e alguns movimentos vão compensando outros.\n",
    "\n",
    "Logo após foi criada uma matriz de translação para ser utilizada como argumento na função `cv.warpAffine` que é quem realmente fará o deslocamento do frame atual. Na matriz, as variáveis acumuladoras são utilizadas para indicar o valor do deslocamento em ambos os eixos cartesianos. Nessa função também é passado como argumento o tamanho da imagem final, que é fixado como o tamanho do frame atual antes das transformações de corte da janela. Isso garante que o deslocamento do frame atual será na imagem inteira e a imagem exibida terá o tamanho completo do frame atual sempre, mesmo que a janela central seja bem menor.\n",
    "\n",
    "O vídeo com a imagem estabilizada é exibido e antes de concluir o loop, o \"frame anterior\" que será utilizado na próxima rodada do laço para calcular o fluxo é atualizado para o \"frame atual\" e quando o loop começa novamente, todo o processo apresentado acima dentro dele é repetido.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cap = cv.VideoCapture(0)\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "# Constants for the crop size\n",
    "xMin = int(frame1.shape[0]/2)-25\n",
    "yMin = int(frame1.shape[1]/2)-25\n",
    "xMax = int(frame1.shape[0]/2)+25\n",
    "yMax = int(frame1.shape[1]/2)+25\n",
    "\n",
    "frame1crop = frame1[yMin:yMax,xMin:xMax] # this is all there is to cropping\n",
    "prvs = cv.cvtColor(frame1crop,cv.COLOR_BGR2GRAY)\n",
    "somax = 0\n",
    "somay = 0\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    cropImg = frame2[yMin:yMax,xMin:xMax] # this is all there is to cropping\n",
    "\n",
    "    next = cv.cvtColor(cropImg,cv.COLOR_BGR2GRAY)\n",
    "    flow = cv.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    avflowx = np.average(flow[:,:,0])\n",
    "    avflowy = np.average(flow[:,:,1])\n",
    "    flowx = avflowx * (-1.0)\n",
    "    flowy = avflowy * (-1.0)\n",
    "    somax += flowx\n",
    "    somay += flowy\n",
    "    translation_matrix = np.float32([[1,0,int(somax)],[0,1,int(somay)]])\n",
    "    img_translation = cv.warpAffine(frame2, translation_matrix, (frame2.shape[1], frame2.shape[0]))\n",
    "    \n",
    "    cv.imshow('Imagem estabilizada',img_translation)    \n",
    "    \n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv.imwrite('opticalfb.png',img_translation)\n",
    "    prvs = next\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A implementação apresentada acima tem limitações que podem ser reconhecidas como possíveis futuras implementações com o objetivo de melhorar este sistema de estabilização de imagens. Algumas delas seriam:\n",
    "    \n",
    "    - Compensação não apenas no eixo x e y do deslocamento, mas também para rotações no eixo y (profundidade).\n",
    "    - Não há um tratamento de compensação nas faixas pretas laterais que aparecem quando acontece o deslocamento, isso poderia ter sido realizado com as funções scaling ou resize, também do opencv."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
